








import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.decomposition import PCA
from pandas.tseries.offsets import DateOffset
import matplotlib.pyplot as plt
from dateutil.relativedelta import relativedelta
import warnings
warnings.filterwarnings("ignore")











file_path = '../data/treasury_quotes_2024-10-31.xlsx'
selected_quotes = pd.read_excel(file_path, sheet_name='selected quotes')
df = selected_quotes
df.set_index("KYTREASNO", inplace=True)
df





def get_coupon_dates(quote_date, maturity_date):
    quote_date = pd.to_datetime(quote_date)
    maturity_date = pd.to_datetime(maturity_date)
    coupon_dates = pd.date_range(start=quote_date, end=maturity_date, freq=DateOffset(months=6))
    coupon_dates = coupon_dates[coupon_dates > quote_date]
    return coupon_dates

def create_cashflow_matrix(quotes):
    quotes = quotes[~quotes['type'].isin(['TIPS Note', 'TIPS bond'])].copy()
    quotes['quote date'] = pd.to_datetime(quotes['quote date'])
    quotes['maturity date'] = pd.to_datetime(quotes['maturity date'])
    ref_date = quotes['quote date'].iloc[0]
    cf_dict = {}
    all_dates = set()
    for i, row in quotes.iterrows():
        maturity = row['maturity date']
        coupon_rate = row['cpn rate']
        coupon_payment = coupon_rate / 2
        coupon_dates = get_coupon_dates(ref_date, maturity)
        cashflows = {}
        for d in coupon_dates:
            cashflows[d] = coupon_payment
            all_dates.add(d)
        if maturity in cashflows:
            cashflows[maturity] += 100
        else:
            cashflows[maturity] = 100
            all_dates.add(maturity)
        cf_dict[i] = cashflows
    all_dates = sorted(all_dates)
    CF = pd.DataFrame(0, index=quotes.index, columns=all_dates)
    for i, cashflows in cf_dict.items():
        for d, amount in cashflows.items():
            CF.loc[i, d] = amount
    CF = CF.resample('M', axis=1).sum()
    CF = CF.loc[:, (CF != 0).any()]
    CF = CF.fillna(0).sort_index(axis=1)
    return CF


CF = create_cashflow_matrix(df)
CF





def discount_to_intrate(discount, maturity, n_compound=2):
    return n_compound * (discount ** (-1/(n_compound * maturity)) - 1)

def estimate_spot_factors(CF, quotes, n_compound=2):
    prices = quotes['price'].loc[CF.index].values
    discount_factors = np.linalg.solve(CF.values, prices)
    spot = pd.DataFrame(discount_factors, index=CF.index, columns=['discount factor'])
    spot.insert(0, 'ttm', quotes['ttm'])
    spot = spot.reset_index(drop=True).set_index('ttm')
    spot['rate'] = discount_to_intrate(spot['discount factor'], spot.index.values, n_compound=n_compound)
    return spot


spot = estimate_spot_factors(CF, selected_quotes, n_compound=2)
fig, ax = plt.subplots(2, 1, figsize=(10, 10))
spot['discount factor'].plot(ax=ax[0], title='Discount Factor')
spot['rate'].plot(ax=ax[1], title='Spot Rate')
display(spot)
plt.tight_layout()
plt.show()





def intrate_to_discount(intrate, maturity, n_compound=2):
    return 1 / (1 + intrate/n_compound)**(n_compound * maturity)

fig, ax = plt.subplots(figsize=(10,6))
ax.plot(spot.index, spot['discount factor'], marker='o', linestyle='-')
ax.set_xlabel('Time-to-Maturity (years)')
ax.set_ylabel('Discount Factor')
ax.set_title('Discount Factors vs. Time-to-Maturity')
plt.tight_layout()
plt.show()

semiannual_rates = spot['rate']
continuous_rates = -np.log(spot['discount factor']) / spot.index.values

fig, ax = plt.subplots(figsize=(10,6))
ax.plot(spot.index, semiannual_rates, marker='o', linestyle='-', label='Semiannually Compounded Rate')
ax.plot(spot.index, continuous_rates, marker='x', linestyle='--', label='Continuously Compounded Rate')
ax.set_xlabel('Time-to-Maturity (years)')
ax.set_ylabel('Rate')
ax.set_title('Discount Rates vs. Time-to-Maturity')
ax.legend()
plt.tight_layout()
plt.show()





COMPOUNDING = 2
rADJ = 0.005
CFadj = CF + rADJ/2 * 100 * (CF > 0)
discadj = spot['rate'] + rADJ
spot['discount adjusted'] = intrate_to_discount(discadj, spot.index.values, n_compound=COMPOUNDING)
pxadj = pd.DataFrame(CFadj.values @ spot[['discount adjusted']].values, index=CFadj.index, columns=['price adjusted'])
px = selected_quotes['dirty price'].loc[pxadj.index]
price_comp = pd.concat([px, pxadj], axis=1)
price_comp.style.format('{:.2f}')
display(price_comp)








DATE = '2024-10-31'
filepath = f'../data/treasury_quotes_{DATE}.xlsx'
quotes = pd.read_excel(filepath, sheet_name='quotes').set_index('KYTREASNO')
quotes['quote date'] = pd.to_datetime(quotes['quote date'])
quotes['maturity date'] = pd.to_datetime(quotes['maturity date'])
quotes





import pandas as pd
import numpy as np
from datetime import datetime
from pandas.tseries.offsets import DateOffset

def get_coupon_dates_backward(quote_date, maturity_date):
    quote_date = pd.to_datetime(quote_date)
    maturity_date = pd.to_datetime(maturity_date)
    coupon_dates = []
    current_date = maturity_date
    while current_date > quote_date:
        coupon_dates.append(current_date)
        current_date -= DateOffset(months=6)
    coupon_dates.sort()
    return coupon_dates

def calc_cashflows(quotes):
    cf_dict = {}
    all_dates = set()
    for i, row in quotes.iterrows():
        maturity = row['maturity date']
        coupon_rate = row['cpn rate']
        coupon_payment = coupon_rate / 2
        coupon_dates = get_coupon_dates_backward(row['quote date'], maturity)
        cashflows = {}
        for d in coupon_dates:
            cashflows[d] = coupon_payment
            all_dates.add(d)
        if maturity in cashflows:
            cashflows[maturity] += 100
        else:
            cashflows[maturity] = 100
            all_dates.add(maturity)
        cf_dict[i] = cashflows
    all_dates = sorted(all_dates)
    CF = pd.DataFrame(0, index=quotes.index, columns=all_dates)
    for i, cashflows in cf_dict.items():
        for d, amount in cashflows.items():
            CF.loc[i, d] = amount
    return CF



quotes = quotes[quotes['ytm'].notnull() & (quotes['ytm'] >= 0)]

CF = calc_cashflows(quotes)
CF = CF.loc[:, (CF != 0).any(axis=0)]

display(CF)

largest_sum_column = CF.sum().idxmax()
most_nonzero_column = (CF != 0).sum().idxmax()

print(f"Date paying the most cash: {largest_sum_column:%Y-%m-%d}")
print(f"Date with the most paying bonds: {most_nonzero_column:%Y-%m-%d}")




















file_path = '../data/yields.xlsx'
yields_df = pd.read_excel(file_path, sheet_name='yields')
yields_df





maturities = list(map(int, yields_df.columns[1:]))

factors = pd.DataFrame(index=yields_df.index)
factors['level'] = yields_df[maturities].mean(axis=1)
factors['slope'] = yields_df[30] - yields_df[1]
factors['curvature'] = -yields_df[1] + 2*yields_df[10] - yields_df[30]
factors.head()


correlation_matrix = factors.corr()
correlation_matrix


mean_factors = factors.mean()
mean_factors.to_frame().rename(columns={0:"Mean Factors"})


vol_factors = factors.std()
vol_factors.to_frame().rename(columns={0:"Vol Factors"})





pca = PCA() 
pca.fit(yields_df[yields_df.columns[1:]])

explained_variance_ratio = pca.explained_variance_ratio_
print("Explained Variance Ratio by each component):")
for i, ratio in enumerate(explained_variance_ratio):
    print(f"PC{i+1}: {ratio}\n")

cumulative_ratio = np.cumsum(explained_variance_ratio)
print("Cumulative Explained Variance Ratio:")
for i, ratio in enumerate(cumulative_ratio, ):
    print(f"Till PC{i+1}: {ratio}\n")


x_axis = np.arange(1, len(explained_variance_ratio) + 1)
plt.figure(figsize=(8, 5))
plt.plot(x_axis, explained_variance_ratio, marker='o', linestyle='-', color='skyblue', 
         label='Individual EVR')
plt.plot(x_axis, cumulative_ratio, marker='o', linestyle='-', color='darkblue', 
         label='Cumulative EVR')

plt.xticks(x_axis) 
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained & Cumulative Variance Ratio')
plt.legend()
plt.tight_layout()
plt.show()


import seaborn as sns
loadings_pc1 = pca.components_[0]
loadings_pc2 = pca.components_[1]
loadings_pc3 =  pca.components_[2]
loadings_df = pd.DataFrame(
    [loadings_pc1, loadings_pc2, loadings_pc3],
    index=['PC1', 'PC2', 'PC3'],
    columns=yields_df.columns[1:]  
)
loadings_df


plt.figure(figsize=(8, 4))
sns.heatmap(
    loadings_df, 
    annot=True,       
    cmap='vlag',      
    center=0
)
plt.title('Heat Map of First Two PC Loadings')
plt.ylabel('Principal Components')
plt.xlabel('Maturities')
plt.tight_layout()
plt.show()





compare_df = pd.concat([factors[['level', 'slope', 'curvature']], loadings_df.T[['PC1', 'PC2', 'PC3']]], axis=1)

corr_matrix = compare_df.corr()
corr_matrix


corr_level_pc1 = corr_matrix.loc['level', 'PC1']
corr_slope_pc2 = corr_matrix.loc['slope', 'PC2']

print(f"Correlation (Ad-hoc level, PC1): {corr_level_pc1:.4f}")
print(f"Correlation (Ad-hoc slope, PC2): {corr_slope_pc2:.4f}")



